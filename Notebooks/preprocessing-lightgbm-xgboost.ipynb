{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "626a0af60cd86c7fbc9b4c852c05ba135678caf9"
   },
   "outputs": [],
   "source": [
    "#Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA, TruncatedSVD, FastICA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.manifold import TSNE\n",
    "import gc\n",
    "#Plotting\n",
    "import seaborn as sns\n",
    "\n",
    "#Models\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "660eddcbd4e1a2d57136b7023086890c1e0bb2bd"
   },
   "source": [
    "## Load the files and get a brief overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "de4e270e1c277cc96508aa0595c79c5d8ef2dfc3"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\", index_col=\"tripid\")\n",
    "\n",
    "test_df = pd.read_csv(\"test.csv\", index_col=\"tripid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "d9c79a158d5bf52352200b50eb933cd42c0662d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>additional_fare</th>\n",
       "      <th>duration</th>\n",
       "      <th>meter_waiting</th>\n",
       "      <th>meter_waiting_fare</th>\n",
       "      <th>meter_waiting_till_pickup</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>drop_time</th>\n",
       "      <th>pick_lat</th>\n",
       "      <th>pick_lon</th>\n",
       "      <th>drop_lat</th>\n",
       "      <th>drop_lon</th>\n",
       "      <th>fare</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tripid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189123628</th>\n",
       "      <td>10.5</td>\n",
       "      <td>834.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>11/1/2019 0:20</td>\n",
       "      <td>11/1/2019 0:34</td>\n",
       "      <td>6.86252</td>\n",
       "      <td>79.8993</td>\n",
       "      <td>6.90330</td>\n",
       "      <td>79.8783</td>\n",
       "      <td>270.32</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189125358</th>\n",
       "      <td>10.5</td>\n",
       "      <td>791.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>11/1/2019 0:56</td>\n",
       "      <td>11/1/2019 1:09</td>\n",
       "      <td>6.88589</td>\n",
       "      <td>79.8984</td>\n",
       "      <td>6.91373</td>\n",
       "      <td>79.8923</td>\n",
       "      <td>197.85</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189125719</th>\n",
       "      <td>10.5</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>61.0</td>\n",
       "      <td>11/1/2019 1:08</td>\n",
       "      <td>11/1/2019 1:26</td>\n",
       "      <td>6.90839</td>\n",
       "      <td>79.8651</td>\n",
       "      <td>6.93669</td>\n",
       "      <td>79.9146</td>\n",
       "      <td>301.64</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189127273</th>\n",
       "      <td>10.5</td>\n",
       "      <td>598.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>15.6638</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11/1/2019 2:27</td>\n",
       "      <td>11/1/2019 2:37</td>\n",
       "      <td>6.92570</td>\n",
       "      <td>79.8895</td>\n",
       "      <td>6.92748</td>\n",
       "      <td>79.8971</td>\n",
       "      <td>82.30</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189128020</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/1/2019 3:34</td>\n",
       "      <td>11/1/2019 3:51</td>\n",
       "      <td>6.87441</td>\n",
       "      <td>79.8615</td>\n",
       "      <td>6.84478</td>\n",
       "      <td>79.9290</td>\n",
       "      <td>358.39</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           additional_fare  duration  meter_waiting  meter_waiting_fare  \\\n",
       "tripid                                                                    \n",
       "189123628             10.5     834.0           56.0              0.0000   \n",
       "189125358             10.5     791.0           47.0              0.0000   \n",
       "189125719             10.5    1087.0           80.0              0.0000   \n",
       "189127273             10.5     598.0          271.0             15.6638   \n",
       "189128020              NaN       NaN            NaN                 NaN   \n",
       "\n",
       "           meter_waiting_till_pickup     pickup_time       drop_time  \\\n",
       "tripid                                                                 \n",
       "189123628                       64.0  11/1/2019 0:20  11/1/2019 0:34   \n",
       "189125358                      134.0  11/1/2019 0:56  11/1/2019 1:09   \n",
       "189125719                       61.0  11/1/2019 1:08  11/1/2019 1:26   \n",
       "189127273                       68.0  11/1/2019 2:27  11/1/2019 2:37   \n",
       "189128020                        NaN  11/1/2019 3:34  11/1/2019 3:51   \n",
       "\n",
       "           pick_lat  pick_lon  drop_lat  drop_lon    fare    label  \n",
       "tripid                                                              \n",
       "189123628   6.86252   79.8993   6.90330   79.8783  270.32  correct  \n",
       "189125358   6.88589   79.8984   6.91373   79.8923  197.85  correct  \n",
       "189125719   6.90839   79.8651   6.93669   79.9146  301.64  correct  \n",
       "189127273   6.92570   79.8895   6.92748   79.8971   82.30  correct  \n",
       "189128020   6.87441   79.8615   6.84478   79.9290  358.39  correct  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "dcf10858e996e58f4fb282558c8c59cf932ea3e9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>additional_fare</th>\n",
       "      <th>duration</th>\n",
       "      <th>meter_waiting</th>\n",
       "      <th>meter_waiting_fare</th>\n",
       "      <th>meter_waiting_till_pickup</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>drop_time</th>\n",
       "      <th>pick_lat</th>\n",
       "      <th>pick_lon</th>\n",
       "      <th>drop_lat</th>\n",
       "      <th>drop_lon</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tripid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>213284604</th>\n",
       "      <td>10.5</td>\n",
       "      <td>924</td>\n",
       "      <td>42</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>148</td>\n",
       "      <td>2/1/2020 0:38</td>\n",
       "      <td>2/1/2020 0:53</td>\n",
       "      <td>6.83454</td>\n",
       "      <td>79.8750</td>\n",
       "      <td>6.77490</td>\n",
       "      <td>79.8840</td>\n",
       "      <td>289.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213286352</th>\n",
       "      <td>10.5</td>\n",
       "      <td>4249</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>91</td>\n",
       "      <td>2/1/2020 1:02</td>\n",
       "      <td>2/1/2020 2:13</td>\n",
       "      <td>6.91168</td>\n",
       "      <td>79.8723</td>\n",
       "      <td>6.55091</td>\n",
       "      <td>79.9706</td>\n",
       "      <td>1912.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213293973</th>\n",
       "      <td>10.5</td>\n",
       "      <td>1552</td>\n",
       "      <td>255</td>\n",
       "      <td>2.6588</td>\n",
       "      <td>23</td>\n",
       "      <td>2/1/2020 5:02</td>\n",
       "      <td>2/1/2020 5:28</td>\n",
       "      <td>6.92145</td>\n",
       "      <td>79.8478</td>\n",
       "      <td>6.90539</td>\n",
       "      <td>79.8989</td>\n",
       "      <td>394.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213294622</th>\n",
       "      <td>10.5</td>\n",
       "      <td>462</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>198</td>\n",
       "      <td>2/1/2020 5:30</td>\n",
       "      <td>2/1/2020 5:38</td>\n",
       "      <td>6.77433</td>\n",
       "      <td>79.9416</td>\n",
       "      <td>6.80401</td>\n",
       "      <td>79.9407</td>\n",
       "      <td>154.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213298687</th>\n",
       "      <td>10.5</td>\n",
       "      <td>814</td>\n",
       "      <td>392</td>\n",
       "      <td>12.3692</td>\n",
       "      <td>69</td>\n",
       "      <td>2/1/2020 7:00</td>\n",
       "      <td>2/1/2020 7:14</td>\n",
       "      <td>6.97968</td>\n",
       "      <td>79.9130</td>\n",
       "      <td>6.98875</td>\n",
       "      <td>79.8914</td>\n",
       "      <td>147.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           additional_fare  duration  meter_waiting  meter_waiting_fare  \\\n",
       "tripid                                                                    \n",
       "213284604             10.5       924             42              2.4486   \n",
       "213286352             10.5      4249             20              0.0000   \n",
       "213293973             10.5      1552            255              2.6588   \n",
       "213294622             10.5       462             16              0.0000   \n",
       "213298687             10.5       814            392             12.3692   \n",
       "\n",
       "           meter_waiting_till_pickup    pickup_time      drop_time  pick_lat  \\\n",
       "tripid                                                                         \n",
       "213284604                        148  2/1/2020 0:38  2/1/2020 0:53   6.83454   \n",
       "213286352                         91  2/1/2020 1:02  2/1/2020 2:13   6.91168   \n",
       "213293973                         23  2/1/2020 5:02  2/1/2020 5:28   6.92145   \n",
       "213294622                        198  2/1/2020 5:30  2/1/2020 5:38   6.77433   \n",
       "213298687                         69  2/1/2020 7:00  2/1/2020 7:14   6.97968   \n",
       "\n",
       "           pick_lon  drop_lat  drop_lon     fare  \n",
       "tripid                                            \n",
       "213284604   79.8750   6.77490   79.8840   289.27  \n",
       "213286352   79.8723   6.55091   79.9706  1912.70  \n",
       "213293973   79.8478   6.90539   79.8989   394.00  \n",
       "213294622   79.9416   6.80401   79.9407   154.32  \n",
       "213298687   79.9130   6.98875   79.8914   147.47  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d55aecff54c8aa6bdd163167f058d49cf33df10c"
   },
   "source": [
    "### Set up train and test X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "0686ab850c7b0d29135f6d897966ee29f72d21ab"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "loop of ufunc does not support argument 0 of type str which has no callable log1p method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'log1p'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-defa09b6ceeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ID\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: loop of ufunc does not support argument 0 of type str which has no callable log1p method"
     ]
    }
   ],
   "source": [
    "X_train = train_df.drop([\"label\"], axis=1)\n",
    "y_train = np.log1p(train_df[\"label\"].values)\n",
    "\n",
    "X_test = test_df.drop([\"ID\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "2aa4b37baf6d628b9a450de45f3928d0a6f01627"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17176 entries, 189123628 to 213817296\n",
      "Data columns (total 13 columns):\n",
      "additional_fare              16974 non-null float64\n",
      "duration                     16974 non-null float64\n",
      "meter_waiting                16974 non-null float64\n",
      "meter_waiting_fare           16974 non-null float64\n",
      "meter_waiting_till_pickup    16974 non-null float64\n",
      "pickup_time                  17176 non-null object\n",
      "drop_time                    17176 non-null object\n",
      "pick_lat                     17176 non-null float64\n",
      "pick_lon                     17176 non-null float64\n",
      "drop_lat                     17176 non-null float64\n",
      "drop_lon                     17176 non-null float64\n",
      "fare                         17039 non-null float64\n",
      "label                        17176 non-null object\n",
      "dtypes: float64(10), object(3)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "95178959a699263a89ca0a86a6fd4a8bda5db57d"
   },
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6f7876a1bce352394beb8ddd7cfac0e475cf92c2"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "35c7d9836c1757f90d8977e4034e651cae19f634"
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8ef2f5162ad83fadb3cacad2ac4c05452a3617b4"
   },
   "source": [
    "### Checking for NaN values and removing constant features in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c7eb68cd08ae67704af52cbe2a14193b58fe3b35"
   },
   "outputs": [],
   "source": [
    "print(\"Total Train Features with NaN Values = \" + str(train_df.columns[train_df.isnull().sum() != 0].size))\n",
    "if (train_df.columns[train_df.isnull().sum() != 0].size):\n",
    "    print(\"Features with NaN => {}\".format(list(train_df.columns[train_df.isnull().sum() != 0])))\n",
    "    train_df[train_df.columns[train_df.isnull().sum() != 0]].isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1641ac15e5b2adb5a177f844bae0c50fa73348a8"
   },
   "outputs": [],
   "source": [
    "zero_count = []\n",
    "for col in X_train.columns[2:]:\n",
    "    zero_count.append([i[1] for i in list(X_train[col].value_counts().items()) if i[0] == 0][0])\n",
    "    \n",
    "print('{0} features of 4491 have zeroes in 99% or more samples.'.format(len([i for i in zero_count if i >= 4459 * 0.99])))\n",
    "print('{0} features of 4491 have zeroes in 98% or more samples.'.format(len([i for i in zero_count if i >= 4459 * 0.98])))\n",
    "print('{0} features of 4491 have zeroes in 97% or more samples.'.format(len([i for i in zero_count if i >= 4459 * 0.97])))\n",
    "print('{0} features of 4491 have zeroes in 96% or more samples.'.format(len([i for i in zero_count if i >= 4459 * 0.96])))\n",
    "print('{0} features of 4491 have zeroes in 95% or more samples.'.format(len([i for i in zero_count if i >= 4459 * 0.95])))\n",
    "\n",
    "cols_to_drop = [col for col in X_train.columns[2:] if [i[1] for i in list(X_train[col].value_counts().items()) if i[0] == 0][0] >= 4459 * 0.98]\n",
    "\n",
    "X_train.drop(cols_to_drop, axis=1, inplace=True)\n",
    "X_test.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print('\\nTrain shape: {}\\nTest shape: {}'.format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7e1cc0ebdb1fcc4f025d859d098a34b4870abe03",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colsToRemove = []\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].std() == 0: \n",
    "        colsToRemove.append(col)\n",
    "        \n",
    "# remove constant columns in the training set\n",
    "train_df.drop(colsToRemove, axis=1, inplace=True)\n",
    "\n",
    "# remove constant columns in the test set\n",
    "test_df.drop(colsToRemove, axis=1, inplace=True) \n",
    "\n",
    "print(\"Removed `{}` Constant Columns\\n\".format(len(colsToRemove)))\n",
    "print(colsToRemove)\n",
    "print('\\nTrain shape: {}\\nTest shape: {}'.format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "30f852b466b6adf961052d8262ea18c8c38787aa"
   },
   "source": [
    "### Removing duplicated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a0d384841b2278b7fe65b9445f05603312890a32"
   },
   "outputs": [],
   "source": [
    "colsToRemove = []\n",
    "colsScaned = []\n",
    "dupList = {}\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "for i in range(len(columns)-1):\n",
    "    v = X_train[columns[i]].values\n",
    "    dupCols = []\n",
    "    for j in range(i+1,len(columns)):\n",
    "        if np.array_equal(v, X_train[columns[j]].values):\n",
    "            colsToRemove.append(columns[j])\n",
    "            if columns[j] not in colsScaned:\n",
    "                dupCols.append(columns[j]) \n",
    "                colsScaned.append(columns[j])\n",
    "                dupList[columns[i]] = dupCols\n",
    "                \n",
    "# remove duplicate columns in the training set\n",
    "X_train.drop(colsToRemove, axis=1, inplace=True) \n",
    "\n",
    "# remove duplicate columns in the testing set\n",
    "X_test.drop(colsToRemove, axis=1, inplace=True)\n",
    "\n",
    "print(\"Removed `{}` Duplicate Columns\\n\".format(len(dupList)))\n",
    "print(dupList)\n",
    "\n",
    "print('\\nTrain shape: {}\\nTest shape: {}'.format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "152531ef2c22aaebaf2ec5e32e949a8e5cedf856"
   },
   "source": [
    "### Drop Sparse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e6b1279706c84fd8c08b0a2a35ab539663d22c25",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_sparse(train, test):\n",
    "    flist = [x for x in train.columns if not x in ['ID','target']]\n",
    "    for f in flist:\n",
    "        if len(np.unique(train[f]))<2:\n",
    "            train.drop(f, axis=1, inplace=True)\n",
    "            test.drop(f, axis=1, inplace=True)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e41ab5ad0b7eb71997386de546ee89dea3fd608a"
   },
   "outputs": [],
   "source": [
    "X_train, X_test = drop_sparse(X_train, X_test)\n",
    "\n",
    "print('\\nTrain shape: {}\\nTest shape: {}'.format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "56f23ae2316833c604de8e34b3e82037fe5ab531"
   },
   "source": [
    "## Add Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d61c58344dc4c567701f59dffc3f7993036f01fa"
   },
   "source": [
    "### Sumzeros and Sumvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6ea858f4ab2a63b3c6459c79b3dd5c3c9c810429",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_SumZeros(train, test, features):\n",
    "    flist = [x for x in train.columns if not x in ['ID','target']]\n",
    "    if 'SumZeros' in features:\n",
    "        train.insert(1, 'SumZeros', (train[flist] == 0).astype(int).sum(axis=1))\n",
    "        test.insert(1, 'SumZeros', (test[flist] == 0).astype(int).sum(axis=1))\n",
    "    flist = [x for x in train.columns if not x in ['ID','target']]\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "71fb6a45b144ca5f2eae337167ef32648b57e8be",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train, X_test = add_SumZeros(X_train, X_test, ['SumZeros'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "efbb17e97cddc97fec763becb6a3caf0ef3063e2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_SumValues(train, test, features):\n",
    "    flist = [x for x in train.columns if not x in ['ID','target']]\n",
    "    if 'SumValues' in features:\n",
    "        train.insert(1, 'SumValues', (train[flist] != 0).astype(int).sum(axis=1))\n",
    "        test.insert(1, 'SumValues', (test[flist] != 0).astype(int).sum(axis=1))\n",
    "    flist = [x for x in train.columns if not x in ['ID','target']]\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e55ef947b6cfcc6444f4ee98e1c166309d54a31d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train, X_test = add_SumValues(X_train, X_test, ['SumValues'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "30233b9a85317dadb9d69da629b42b0f019ea6af"
   },
   "source": [
    "### Other Aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "000ed2bdc20e9de1bf0d7c43571262203f801683",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_OtherAgg(train, test, features):\n",
    "    flist = [x for x in train.columns if not x in ['ID','target','SumZeros','SumValues']]\n",
    "    if 'OtherAgg' in features:\n",
    "        train['Mean'] = train.mean(axis=1)\n",
    "        train['Median'] = train.median(axis=1)\n",
    "        train['Mode'] = train.mode(axis=1)\n",
    "        train['Max'] = train.max(axis=1)\n",
    "        train['Var'] = train.var(axis=1)\n",
    "        train['Std'] = train.std(axis=1)\n",
    "        \n",
    "        test['Mean'] = test.mean(axis=1)\n",
    "        test['Median'] = test.median(axis=1)\n",
    "        test['Mode'] = test.mode(axis=1)\n",
    "        test['Max'] = test.max(axis=1)\n",
    "        test['Var'] = test.var(axis=1)\n",
    "        test['Std'] = test.std(axis=1)\n",
    "    flist = [x for x in train.columns if not x in ['ID','target','SumZeros','SumValues']]\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f5cf1e7c6244a8a219673179a7d68cc9aa605004"
   },
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a14b2e04eb3133ec411db7d71bf90505badd0a21",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeans(X_Tr,Xte):\n",
    "    flist = [x for x in X_Tr.columns if not x in ['ID','target']]\n",
    "    flist_kmeans = []\n",
    "    for ncl in range(2,11):\n",
    "        cls = KMeans(n_clusters=ncl)\n",
    "        cls.fit_predict(X_train[flist].values)\n",
    "        X_Tr['kmeans_cluster_'+str(ncl)] = cls.predict(X_Tr[flist].values)\n",
    "        Xte['kmeans_cluster_'+str(ncl)] = cls.predict(Xte[flist].values)\n",
    "        flist_kmeans.append('kmeans_cluster_'+str(ncl))\n",
    "    print(flist_kmeans)\n",
    "    \n",
    "    return X_Tr,Xte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9bba2ea791874effd662d169b63682f5ef05d912"
   },
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fe761a131a937410a81894afca3fb0a63950ba1e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pca(X_Tr,Xte):\n",
    "    flist = [x for x in X_Tr.columns if not x in ['ID','target']]\n",
    "    n_components = 20\n",
    "    flist_pca = []\n",
    "    pca = PCA(n_components=n_components)\n",
    "    x_train_projected = pca.fit_transform(StandardScaler(X_Tr[flist], axis=0))\n",
    "    x_test_projected = pca.transform(StandardScaler(X_test[flist], axis=0))\n",
    "    for npca in range(0, n_components):\n",
    "        X_Tr.insert(1, 'PCA_'+str(npca+1), x_train_projected[:, npca])\n",
    "        Xte.insert(1, 'PCA_'+str(npca+1), x_test_projected[:, npca])\n",
    "        flist_pca.append('PCA_'+str(npca+1))\n",
    "    print(flist_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fa166293adb8196a46a6b6700d7e3ec7857f84d9"
   },
   "outputs": [],
   "source": [
    "print('\\nTrain shape: {}\\nTest shape: {}'.format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b39a986df78d2ed2f9127400511c3a02234b9da7"
   },
   "outputs": [],
   "source": [
    "PERC_TRESHOLD = 0.98   ### Percentage of zeros in each feature ###\n",
    "N_COMP = 97            ### Number of decomposition components ###\n",
    "\n",
    "print(\"\\nStart decomposition process...\")\n",
    "print(\"PCA\")\n",
    "pca = PCA(n_components=N_COMP, random_state=17)\n",
    "pca_results_train = pca.fit_transform(X_train)\n",
    "pca_results_test = pca.transform(X_test)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "print(\"tSVD\")\n",
    "tsvd = TruncatedSVD(n_components=N_COMP, random_state=17)\n",
    "tsvd_results_train = tsvd.fit_transform(X_train)\n",
    "tsvd_results_test = tsvd.transform(X_test)\n",
    "\n",
    "print(\"ICA\")\n",
    "ica = FastICA(n_components=N_COMP, random_state=17)\n",
    "ica_results_train = ica.fit_transform(X_train)\n",
    "ica_results_test = ica.transform(X_test)\n",
    "\n",
    "print(\"GRP\")\n",
    "grp = GaussianRandomProjection(n_components=N_COMP, eps=0.1, random_state=17)\n",
    "grp_results_train = grp.fit_transform(X_train)\n",
    "grp_results_test = grp.transform(X_test)\n",
    "\n",
    "print(\"SRP\")\n",
    "srp = SparseRandomProjection(n_components=N_COMP, dense_output=True, random_state=17)\n",
    "srp_results_train = srp.fit_transform(X_train)\n",
    "srp_results_test = srp.transform(X_test)\n",
    "\n",
    "print(\"Append decomposition components to datasets...\")\n",
    "for i in range(1, N_COMP + 1):\n",
    "    X_train['pca_' + str(i)] = pca_results_train[:, i - 1]\n",
    "    X_test['pca_' + str(i)] = pca_results_test[:, i - 1]\n",
    "    \n",
    "    X_train['ica_' + str(i)] = ica_results_train[:, i - 1]\n",
    "    X_test['ica_' + str(i)] = ica_results_test[:, i - 1]\n",
    "\n",
    "    X_train['tsvd_' + str(i)] = tsvd_results_train[:, i - 1]\n",
    "    X_test['tsvd_' + str(i)] = tsvd_results_test[:, i - 1]\n",
    "\n",
    "    X_train['grp_' + str(i)] = grp_results_train[:, i - 1]\n",
    "    X_test['grp_' + str(i)] = grp_results_test[:, i - 1]\n",
    "\n",
    "    X_train['srp_' + str(i)] = srp_results_train[:, i - 1]\n",
    "    X_test['srp_' + str(i)] = srp_results_test[:, i - 1]\n",
    "print('\\nTrain shape: {}\\nTest shape: {}'.format(X_train.shape, X_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "64a1ade7100a9b401d60e1cc6ac0a4c6092187e3"
   },
   "outputs": [],
   "source": [
    "print(tsvd.explained_variance_ratio_)\n",
    "sum1 = 0\n",
    "for i in range(len(tsvd.explained_variance_ratio_)):\n",
    "    sum1 = sum1 + tsvd.explained_variance_ratio_[i]\n",
    "\n",
    "print(sum1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "93ed0e5d83964102334f821160bd4b165115364e"
   },
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for i in range(len(pca.explained_variance_ratio_)):\n",
    "    sum = sum + pca.explained_variance_ratio_[i]\n",
    "\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eba058002a23a7798abe7523ba5a1735904bb600"
   },
   "source": [
    "## Build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f4623ebaa4b34c407125b2d3144c1591903d0bf8"
   },
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2ca46bf1983658d14912188e6aa4e60b8c8d682b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_lgb(train_X, train_y, val_X, val_y, test_X):\n",
    "    params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'dart',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_leaves\": 200,\n",
    "    \"feature_fraction\": 0.50,\n",
    "    \"bagging_fraction\": 0.50,\n",
    "    'bagging_freq': 4,\n",
    "    \"max_depth\": -1,\n",
    "    \"reg_alpha\": 0.3,\n",
    "    \"reg_lambda\": 0.1,\n",
    "    #\"min_split_gain\":0.2,\n",
    "    \"min_child_weight\":10,\n",
    "    'zero_as_missing':True\n",
    "}\n",
    "    \n",
    "#     {'learning_rate':0.008,\n",
    "#         'boosting_type':'gbdt',\n",
    "#         'objective':'regression',\n",
    "#         'metric':'rmse',\n",
    "#         'sub_feature':0.5,\n",
    "#         'num_leaves':180,\n",
    "#         'feature_fraction': 0.5,\n",
    "#         'bagging_fraction': 0.5,\n",
    "#         'min_data':50,\n",
    "#         'max_depth':-1,\n",
    "#         'reg_alpha': 0.3, \n",
    "#         'reg_lambda': 0.1, \n",
    "#         'min_child_weight': 10, \n",
    "#         'verbose': 1,\n",
    "#         'nthread':5,\n",
    "#         'max_bin':512,\n",
    "#         'subsample_for_bin':200,\n",
    "#         'min_split_gain':0.0001,\n",
    "#         'min_child_samples':5\n",
    "#        }\n",
    "\n",
    "\n",
    "#     {\n",
    "#         \"objective\" : \"regression\",\n",
    "#         \"metric\" : \"rmse\",\n",
    "#         \"num_leaves\" : 40,\n",
    "#         \"learning_rate\" : 0.005,\n",
    "#         \"bagging_fraction\" : 0.7,\n",
    "#         \"feature_fraction\" : 0.5,\n",
    "#         \"bagging_frequency\" : 5,\n",
    "#         \"bagging_seed\" : 42,\n",
    "#         \"verbosity\" : -1,\n",
    "#         \"random_seed\": 42\n",
    "#     }\n",
    "#     {\n",
    "#     'task': 'train',\n",
    "#     'boosting_type': 'dart',\n",
    "#     'objective': 'regression',\n",
    "#     'metric': 'rmse',\n",
    "#     \"learning_rate\": 0.01, # Try 0.05\n",
    "#     \"num_leaves\": 200, # 24\n",
    "#     \"feature_fraction\": 0.50, \n",
    "#     \"bagging_fraction\": 0.90,\n",
    "#     'bagging_freq': 4,\n",
    "#     \"max_depth\": -1,\n",
    "#     \"reg_alpha\": 0.3,\n",
    "#     \"reg_lambda\": 0.1,\n",
    "#     #\"min_split_gain\":0.2,\n",
    "#     \"min_child_weight\":10,\n",
    "#     'zero_as_missing':True\n",
    "#     'nthread': 32,\n",
    "#     'lambda_l1':0.1, \n",
    "#     'lambda_l2':0.1,\n",
    "    \n",
    "    \n",
    "# }\n",
    "    \n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, lgtrain, 5000, \n",
    "                      valid_sets=[lgval], \n",
    "                      early_stopping_rounds=100, \n",
    "                      verbose_eval=50, \n",
    "                      evals_result=evals_result)\n",
    "    \n",
    "    pred_test_y = np.expm1(model.predict(test_X, num_iteration=model.best_iteration))\n",
    "    return pred_test_y, model, evals_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0042ea666373d552a73f8a53515976111cff41e4"
   },
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "99b3fdc0f20054c055453817d0f086b3445a87bc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_xgb(train_X, train_y, val_X, val_y, test_X):\n",
    "    params = {'objective': 'reg:linear', 'eval_metric': 'rmse', 'eta': 0.005, 'max_depth': 10, 'subsample': 0.7, 'colsample_bytree': 0.5, 'alpha':0, 'silent': True, 'random_state':5}\n",
    "# {'objective': 'reg:linear','eval_metric': 'rmse','eta': 0.005,'max_depth': 15,'subsample': 0.7,'colsample_bytree': 0.5,'alpha':0,'random_state':42,'silent': True}\n",
    "    \n",
    "    tr_data = xgb.DMatrix(train_X, train_y)\n",
    "    va_data = xgb.DMatrix(val_X, val_y)\n",
    "    \n",
    "    watchlist = [(tr_data, 'train'), (va_data, 'valid')]\n",
    "    \n",
    "    model_xgb = xgb.train(params, tr_data, 2000, watchlist, maximize=False, early_stopping_rounds = 30, verbose_eval=100)\n",
    "    \n",
    "    dtest = xgb.DMatrix(test_X)\n",
    "    xgb_pred_y = np.expm1(model_xgb.predict(dtest, ntree_limit=model_xgb.best_ntree_limit))\n",
    "    \n",
    "    return xgb_pred_y, model_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f2c97a10f22ee74de966f77fed20aec5898da30a"
   },
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7464fe72d2d16fdbe531f8db9ec8cc059339782e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Split data\n",
    "dev_X, val_X, dev_y, val_y = train_test_split(X_train, y_train, test_size = 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "# Training LGB\n",
    "pred_test, model, evals_result = run_lgb(dev_X, dev_y, val_X, val_y, X_test)\n",
    "print(\"LightGBM Training Completed...\")\n",
    "\n",
    "print(\"Features Importance...\")\n",
    "gain = model.feature_importance('gain')\n",
    "featureimp = pd.DataFrame({'feature':model.feature_name(), \n",
    "                   'split':model.feature_importance('split'), \n",
    "                   'gain':100 * gain / gain.sum()}).sort_values('gain', ascending=False)\n",
    "print(featureimp[:15])\n",
    "\n",
    "# Training XGB\n",
    "pred_test_xgb, model_xgb = run_xgb(dev_X, dev_y, val_X, val_y, X_test)\n",
    "print(\"XGB Training Completed...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "74fed90476b39616c6c0a31b7da4092319b9b657"
   },
   "source": [
    "### Create file with submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5067817cb22853c8493fa52acd6caabdafb7d7d1"
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "sub_lgb = pd.DataFrame()\n",
    "sub_lgb[\"target\"] = pred_test\n",
    "sub_lgb[\"ID\"] = sub[\"ID\"]\n",
    "sub_lgb.to_csv(\"sub_lgb.csv\", index=False)\n",
    "\n",
    "sub_xgb = pd.DataFrame()\n",
    "sub_xgb[\"target\"] = pred_test_xgb\n",
    "sub_xgb[\"ID\"] = sub[\"ID\"]\n",
    "sub_lgb.to_csv(\"sub_xgb.csv\", index=False)\n",
    "\n",
    "\n",
    "sub[\"target\"] = (sub_lgb[\"target\"] + sub_xgb[\"target\"] )/2\n",
    "\n",
    "print(sub.head())\n",
    "sub.to_csv('sub_lgb_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d721c23b194f32f7057f4c88b01d1930f29575b4",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03f72468e253921dc9c277482e52d1413b7b2e39",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
